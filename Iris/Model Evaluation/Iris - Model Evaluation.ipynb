{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris - Model Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiKlp0njQp2qmJqC5SJdxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaedul-Islam/Machine_Learning_Projects/blob/master/Iris/Model%20Evaluation/Iris%20-%20Model%20Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLJvSbNgWz1O",
        "colab_type": "text"
      },
      "source": [
        "# **Comparing machine learning models in scikit-learn**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRJtPr0LXbfV",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluation procedure #1: Train and test on the entire dataset**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   Train the model on the **entire dataset**.\n",
        "2.   Test the model on the **same dataset**, and evaluate how well we did by comparing the **predicted** target values with the **true** target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVPjNBO2Wrso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import load_iris function from datasets module\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load \"bunch\" object containing iris dataset and its attributes\n",
        "iris = load_iris()\n",
        "\n",
        "# Create X (features matrix) and y (target)\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8pVVq0DYMGB",
        "colab_type": "code",
        "outputId": "c6c11c09-841f-4706-c639-484b1037c2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1dzg2lSYN8Z",
        "colab_type": "code",
        "outputId": "599fa8c8-deb2-47a3-c21e-5a18739d6709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3xklcBZLiU",
        "colab_type": "text"
      },
      "source": [
        "## **#1. Classifier: Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Igut17ZSqN",
        "colab_type": "code",
        "outputId": "14eec500-6442-4380-b89f-4f7676079704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate the model (using the default parameters)\n",
        "logisticRegressionClassifier = LogisticRegression()\n",
        "\n",
        "print(logisticRegressionClassifier)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NaBWH3raCDe",
        "colab_type": "code",
        "outputId": "7829d262-ee3a-41c3-f6c1-be4eb4a78971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Fit the model with data\n",
        "logisticRegressionClassifier.fit(X, y)\n",
        "\n",
        "# Predict the target values for the observations in X\n",
        "logisticRegressionClassifier.predict(X)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78KwqWaHauYg",
        "colab_type": "code",
        "outputId": "2ef0f7d8-43b6-4fdc-d7ab-1e47a644702b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Store the predicted target values\n",
        "y_prediction = logisticRegressionClassifier.predict(X)\n",
        "\n",
        "# Check how many predictions were generated\n",
        "len(y_prediction)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcVwYMy1bU_-",
        "colab_type": "text"
      },
      "source": [
        "**Classification accuracy (a numerical way how a model performs):**\n",
        "\n",
        "*   **Proportion** of correct predictions. This is known as a evaluation metric. There're many possible evaluation metrics \n",
        "*   Common **evaluation metric** for classification problems: *`metrics`* module from scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU2uE5x1cCSB",
        "colab_type": "code",
        "outputId": "6e31cf7c-bc92-402b-8e7b-ba485f52333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute classification accuracy for the logistic regression model\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.accuracy_score(y, y_prediction))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9zeGp_cdMQ8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   97% of predictions are correct\n",
        "*   Known as **training accuracy** when you train and test the model on the same data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwmtc9zjfBdK",
        "colab_type": "text"
      },
      "source": [
        "## **#2. Classifier: K-Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uQNZTSufNcj",
        "colab_type": "text"
      },
      "source": [
        "### **KNN (K=5)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AXa9fCZffFP",
        "colab_type": "code",
        "outputId": "a0025a7b-1c66-4d1b-fe68-e64c90c3df4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knnClassifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "knnClassifier.fit(X, y)\n",
        "y_prediction = knnClassifier.predict(X)\n",
        "print(metrics.accuracy_score(y, y_prediction))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtb0jXsPgMTj",
        "colab_type": "text"
      },
      "source": [
        "### **KNN (K=1)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T8bVTIhgHFZ",
        "colab_type": "code",
        "outputId": "0ea9201f-3a74-4616-9abe-a492db2c3732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors=1)\n",
        "knnClassifier.fit(X, y)\n",
        "y_prediction = knnClassifier.predict(X)\n",
        "print(metrics.accuracy_score(y, y_prediction))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VewuqYZgsAQ",
        "colab_type": "text"
      },
      "source": [
        "***So, it can be concluded that KNN with K=1 is the best model to use with the Iris dataset.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKNH_h7V2DtO",
        "colab_type": "text"
      },
      "source": [
        "## **Problems with training and testing on the same data**\n",
        "\n",
        "---\n",
        "\n",
        "* Goal is to estimate likely performance of a model on **out-of-sample data** meaning future observations in which we don't know the true target values\n",
        "* But, maximizing training accuracy rewards **overly complex models** that won't necessarily generalize to future cases\n",
        "* Unnecessarily complex models **overfit** the training data. Models that overfit learn the noise in the data rather than the signal.\n",
        "* In the case of KNN, a very low of K creates a high complexity models because if follows the noise in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NJFv8uLsp1a",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluation procedure #2: Train/test split**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
        "2. Train the model on the **training set**.\n",
        "3. Test the model on the **testing set**, and evaluate how well we did.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDTG8E5mKfUd",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/justmarkham/scikit-learn-videos/raw/cec096b944cbd8d8973b728d45275e4c0c6cc139/images/05_overfitting.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-S4lmkWtLYJ",
        "colab_type": "code",
        "outputId": "78510ab1-90cd-4764-f36e-9b53c46c0464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print the shapes of X and y\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zhdKmAU_wr37"
      },
      "source": [
        "### **#1. Classifier: Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9oNG8Jdt07t",
        "colab_type": "text"
      },
      "source": [
        "**STEP 1: Split X and y into training and testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Bh6dKJtd9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOn6t3xCaD9",
        "colab_type": "text"
      },
      "source": [
        "*`test_size`*: There's no general as to what percentage is the best. But it's usual to use 20% to 40% of the data for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zprg_ZHABIFM",
        "colab_type": "text"
      },
      "source": [
        "Running the **train_test_split** on **X** and **y** will yeild to as something like below.\n",
        "![alt text](https://github.com/justmarkham/scikit-learn-videos/raw/cec096b944cbd8d8973b728d45275e4c0c6cc139/images/05_train_test_split.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvGRGXx3COI_",
        "colab_type": "text"
      },
      "source": [
        "**What did this accomplish?**\n",
        "\n",
        "* Model can be trained and tested on **different data**\n",
        "* Target values are known for the testing set, and thus **predictions can be evaluated**\n",
        "* **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwqtaEHiubjw",
        "colab_type": "code",
        "outputId": "ae0b55e1-e6ff-4338-ea81-020c6b9bb33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print the shapes of the new X objects\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 4)\n",
            "(60, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBhdcRUtusLw",
        "colab_type": "code",
        "outputId": "8489ff0f-bed1-4eb5-dd08-22329542b241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print the shapes of the new y objects\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90,)\n",
            "(60,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej2l5XywvIz4",
        "colab_type": "text"
      },
      "source": [
        "**STEP 2: Train the model on the training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvPnLmhRvITJ",
        "colab_type": "code",
        "outputId": "3b056d62-7540-4b2d-f4fd-bb1697473c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "logisticRegressionClassifier = LogisticRegression()\n",
        "logisticRegressionClassifier.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EucaU3-Sv3hC",
        "colab_type": "text"
      },
      "source": [
        "**STEP 3: Make predictions on the testing set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5efbt7-Xvlzy",
        "colab_type": "code",
        "outputId": "cc93a05a-aafc-44fc-ad76-e1370bc1aeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_prediction = logisticRegressionClassifier.predict(X_test)\n",
        "\n",
        "# Compare actual target values (y_test) with predicted predicted values (y_pred)\n",
        "print(metrics.accuracy_score(y_test, y_prediction))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EOngOyd2wjfk"
      },
      "source": [
        "### **#2. Classifier: K-Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEOEmB1Sxf_R",
        "colab_type": "text"
      },
      "source": [
        "### **KNN (K=5)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFWdn7dCxBiz",
        "colab_type": "code",
        "outputId": "f508e829-9aa6-47c8-a534-cdc4b03a58b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "knnClassifier.fit(X_train, y_train)\n",
        "y_prediction = knnClassifier.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_prediction))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lkymwYQvyD_L"
      },
      "source": [
        "### **KNN (K=1)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7M1qZtjyGHP",
        "colab_type": "code",
        "outputId": "79e2344c-b69f-4fca-83c4-34a59f26106b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors = 1)\n",
        "knnClassifier.fit(X_train, y_train)\n",
        "y_prediction = knnClassifier.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_prediction))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CP5qyafEsxV",
        "colab_type": "text"
      },
      "source": [
        "***So, it can be concluded that KNN with K=5 and Logistic Regression are likely to be the best model to use with the Iris dataset.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz6BrjurFQGH",
        "colab_type": "text"
      },
      "source": [
        "### **Can we locate an even better value for K?**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOxj3DsfFU-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try K = 1 through K = 25 and record testing accuracy\n",
        "kRange = range(1, 26)\n",
        "knnAccuracyScores = []\n",
        "\n",
        "for K in kRange:\n",
        "  knnClassifier = KNeighborsClassifier(n_neighbors = K)\n",
        "  knnClassifier.fit(X_train, y_train)\n",
        "  y_prediction = knnClassifier.predict(X_test)\n",
        "  knnAccuracyScores.append(metrics.accuracy_score(y_test, y_prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9zIUKeWLzDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2bbc88f9-8a0e-4603-d1b0-076b05d29acb"
      },
      "source": [
        "# Import Matplotlib (scientific plotting library)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Allow plots to appear within the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot the relationship between K and testing accuracy\n",
        "plt.plot(kRange, knnAccuracyScores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Testing Accuracy')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Testing Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHt4JaVoMu2F",
        "colab_type": "text"
      },
      "source": [
        "**Decision from the above graph:**\n",
        "\n",
        "* In general, as the value of K increases there appears to be rise in the **Training accuracy** and then it falls. This type of fall is quite typical when examining the relationship between model complexity and **Training accuracy**.\n",
        "*   **Training accuracy** rises as model complexity increases. Model complexity for KNN is determined by the value of K\n",
        "* **Testing accuracy** penalizes models that are too complex or not complex enough. There will be a maximum testing accuracy when the model has the right level of complexity. In this case, the highest accuracy is from K = 6 to K = 17 and it can be tentatively conclude that a K value in that range would be better than K = 5. However, as this dataset is so small and this is a easy classification task, it's hard to reliably say whether the behavior in this onw plot will indeed generalize. Regardless, plotting **Testing accuracy** vs **Model Complexity** is a very useful way to tune any parameters that relate to **Model Complexity**\n",
        "* For KNN models, complexity is determined by the value of K (lower value = more complex)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpxzCe0kQJFU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Making predictions on out-of-sample data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UoHFmEQcFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9a644b4-b271-4d98-b7b3-9d02b5be0a9d"
      },
      "source": [
        "# Instantiate the model with the best known parameters\n",
        "# Since 11 is in the middle of the K range with the highest testing accuracy, it can called the best model in this case\n",
        "knnClassifier = KNeighborsClassifier(n_neighbors = 11)\n",
        "\n",
        "# train the model with X and y (not X_train and y_train)\n",
        "knnClassifier.fit(X, y)\n",
        " \n",
        "# make a prediction for an out-of-sample observation\n",
        "X_new = [[3, 5, 4, 2]]\n",
        "knnClassifier.predict(X_new)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Hgo_jJR76V",
        "colab_type": "text"
      },
      "source": [
        "### **Downsides of train/test split?**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* Provides a **high-variance estimate** of out-of-sample accuracy. Meaning that it can change a lot depending uping which observations happen to be in the training set vs the testing set.\n",
        "* **K-fold cross-validation** overcomes this limitation\n",
        "* But, train/test split is still useful because of its **flexibility** and **speed**"
      ]
    }
  ]
}